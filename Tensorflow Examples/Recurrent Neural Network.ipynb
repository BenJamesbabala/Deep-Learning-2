{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*UkI9za9zTR-HL8uM15Wmzw.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this function will help us in generating images which will help us in knowing what we are doing\n",
    "from IPython.display import Image\n",
    "#to get content from a web page we import HTML\n",
    "from IPython.core.display import HTML \n",
    "#bridge gap between python 2 and python 3\n",
    "from __future__ import print_function, division\n",
    "#generate some binary input data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*UkI9za9zTR-HL8uM15Wmzw.png\")\n",
    "#shows that RNN that is learning over time and 3 squares are hidden states. Hidden layers in RNN changes over time because we not just feed the input data, we feed input and the previous hidden state data\n",
    "#so when we perform optimization(backpropogation) so it backprops through time and so it remembers what happened in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "\n",
    "#number of times we want to train our network, inside epochs we have batches and it becomes a nested loop\n",
    "num_epochs = 10 #more epochs longer train time better prediction, so its basically a tradeoff between time, accuracy and computation.\n",
    "#how long sequence we want to generate\n",
    "total_series_length = 50000\n",
    "#this means that we are going to save portions of the sequence and we are going to discard the oldest values over time. Its similar to vanishing gradient problem, where we use keep_prob to keep certain part of network and drop rest of it while backpropogating.\n",
    "truncated_backprop_length = 15\n",
    "#number of neurons in our hidden layer, because we have 3 layer RNN that we are building and hidden state we are going to update over time.\n",
    "state_size = 4\n",
    "#since our data is binary and its not classification its sequence to sequence mapping. Classes: 0 and 1 so total:2\n",
    "num_classes = 2\n",
    "# to understand echo_step this might come in handy \n",
    "#https://stats.stackexchange.com/questions/140652/what-is-an-intuitive-explanation-of-echo-state-networks\n",
    "echo_step = 3\n",
    "#each time we consider window size of 5\n",
    "batch_size = 5\n",
    "#how many times we will have to iterate in order to train our model on complete 50000 sequence length\n",
    "#you can also consider truncate as strides in CNN, so we skip some part of network.\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0, 0, 0, ..., 1, 0, 0],\n",
      "       [0, 1, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 1, ..., 1, 0, 0],\n",
      "       [0, 1, 0, ..., 0, 1, 0],\n",
      "       [1, 1, 1, ..., 1, 1, 1]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 1, 1],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 1, 1, 0],\n",
      "       [0, 1, 0, ..., 1, 0, 1]]))\n"
     ]
    }
   ],
   "source": [
    "#Step 1 - Collect data\n",
    "#Now generate the training data, \n",
    "#the input is basically a random binary vector. The output will be the \n",
    "#“echo” of the input, shifted echo_step steps to the right.\n",
    "#Lot of time we want to test out our Neural Networks but we do not want to test out on real world data so we generate data using numpy\n",
    "\n",
    "\n",
    "#Notice the reshaping of the data into a matrix with batch_size rows. \n",
    "#Neural networks are trained by approximating the gradient of loss function \n",
    "#with respect to the neuron-weights, by looking at only a small subset of the data, \n",
    "#also known as a mini-batch.The reshaping takes the whole dataset and puts it into \n",
    "#a matrix, that later will be sliced up into these mini-batches.\n",
    "\n",
    "def generateData():\n",
    "    #We generate a time series data, we generate 50k samples all binary.\n",
    "    #0,1, 50K samples, 50% chance each chosen\n",
    "    #2 means 2 class 0 and 1. total_series is the length of the series we defined earlier and the probability that each of the classes get picked is 50-50.\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    #shift times series 3 steps to the right\n",
    "    # eg: x is 1-10 and echo_step is 3 so y will be 7 8 9 1 2 3 4 5 6 and in next step we pad the first 3 sequence with 0.\n",
    "    # y is exact same series shifted to the right by 3 steps.\n",
    "    y = np.roll(x, echo_step)\n",
    "    #padd beginning 3 values with 0\n",
    "    y[0:echo_step] = 0\n",
    "    #Gives a new shape to an array without changing its data.\n",
    "    #The reshaping takes the whole dataset and puts it into a matrix, \n",
    "    #that later will be sliced up into these mini-batches.\n",
    "    x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)\n",
    "#x and y are correlated with time.\n",
    "#the purpose of all this is toshows how memory is incorporated in RNN.\n",
    "data = generateData()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*aFtwuFsboLV8z5PkEzNLXA.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Schematic of the reshaped data-matrix, arrow curves shows adjacent time-steps that ended up on different rows. \n",
    "#Light-gray rectangle represent a “zero” and dark-gray a “one”.\n",
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*aFtwuFsboLV8z5PkEzNLXA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TensorFlow works by first building up a computational graph, that \n",
    "#specifies what operations will be done. The input and output of this graph\n",
    "#is typically multidimensional arrays, also known as tensors. \n",
    "#The graph, or parts of it can then be executed iteratively in a \n",
    "#session, this can either be done on the CPU, GPU or even a resource \n",
    "#on a remote server.\n",
    "\n",
    "#operations and tensors\n",
    "\n",
    "#The two basic TensorFlow data-structures that will be used in this \n",
    "#example are placeholders and variables. On each run the batch data \n",
    "#is fed to the placeholders, which are “starting nodes” of the \n",
    "#computational graph. Also the RNN-state is supplied in a placeholder, \n",
    "#which is saved from the output of the previous run.\n",
    "\n",
    "#point of reshaping tensor/array was so that we can feed it in to our placeholders which is a gateway through which data flows in to the tensorflow.\n",
    "\n",
    "\n",
    "#Step 2 - Build the Model\n",
    "\n",
    "#datatype, shape (5, 15) 2D array or matrix, batch size shape for later\n",
    "#shape of X and Y are 2 D matrix, float32 since it is 32 bit float.\n",
    "# we can consider echo to be a label, its a mapping between sequences.\n",
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "#and one for the RNN state, 5,4 \n",
    "#initialize the state, because we want to know what is happening in the memory portion of the hidden state.\n",
    "#we feed in the state every time not just feeding the input data at every iteration of training we are also feeding in previous hidden states that we learnt.\n",
    "#so this is the gateway for that hidden state.\n",
    "#in RNN we have placeholders not just for I/P data and labels but also for the state that it learnt before.\n",
    "#so its got a previous state and current state.\n",
    "#so shape of it is going to be batch_size and number of neurons that happened before hand.\n",
    "init_state = tf.placeholder(tf.float32, [batch_size, state_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we build our weights and biases as we have got our placeholders and we have defined our gateways, data is to ready to be fed in to the network.\n",
    "#since it is a 3 layer RNN, we have 2 sets of weights between I/P and hidden layer and hidden layer and O/P.\n",
    "#The weights and biases of the network are declared as TensorFlow variables,\n",
    "#which makes them persistent across runs and enables them to be updated\n",
    "#incrementally for each batch.\n",
    "\n",
    "#3 layer recurrent net, one hidden state\n",
    "\n",
    "#randomly initialize weights\n",
    "#as we know variables can be updated over time unlike constants and placeholders.\n",
    "#its better to initialize randomly than initializing as all zeros.\n",
    "W = tf.Variable(np.random.rand(state_size+1, state_size), dtype=tf.float32)\n",
    "#improves convergence, matrix of 0s\n",
    "#in terms of linear regression y = mx + b, in non-linear model it still offers that anchor point of convergence.\n",
    "#not that y intercept its just an anchor point so that the value we predict our not too far off from what it should be.\n",
    "b = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*n45uYnAfTDrBvG87J-poCA.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*n45uYnAfTDrBvG87J-poCA.jpeg\")\n",
    "#dotted square is looking at the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now it’s time to build the part of the graph that resembles the actual RNN computation, \n",
    "#first we want to split the batch data into adjacent time-steps.\n",
    "\n",
    "# Unstack columns\n",
    "#Unstacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\n",
    "#so a bunch of arrays, 1 batch per time step\n",
    "#we unstack the columns so that we can feed it in our array.\n",
    "#it unstacks the columns in to a set of lists and each of these lists are going to be fed in, remember matrix 1's and 0's we just want 1 array at a time.\n",
    "#unstack matrix in to a 1D array both for I/P and O/P series.\n",
    "inputs_series = tf.unstack(batchX_placeholder, axis=1)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*f2iL4zOkBUBGOpVE7kyajg.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*f2iL4zOkBUBGOpVE7kyajg.png\")\n",
    "#Schematic of the current batch split into columns, the order index is shown on each data-point \n",
    "#and arrows show adjacent time-steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forward pass\n",
    "#here we learn about memory and how it is incorporated in RNN.\n",
    "#update placeholders over time, we can do this in our computation graph but we are going to do this before.\n",
    "#state placeholder\n",
    "#we define our curren state of hidden layer\n",
    "current_state = init_state\n",
    "# track series of states through time and store in this array\n",
    "# this is how we remember the states we store in memory in an array.\n",
    "states_series = []\n",
    "\n",
    "\n",
    "#for each set of inputs\n",
    "#forward pass through the network to get new state value\n",
    "#store all states in memory\n",
    "#for current input in input series for all inputs that we have defined before hand we are going to take the current I/P and we are going to feed it through the network.\n",
    "for current_input in inputs_series:\n",
    "    #format input, reshape it so that its in a shape that our RNN accepts, reshape cirrent_input in to batch_sie * 1.\n",
    "    current_input = tf.reshape(current_input, [batch_size, 1])\n",
    "    #mix both state and input data \n",
    "    input_and_state_concatenated = tf.concat([current_input, current_state],1)  # Increasing number of columns\n",
    "    #before squashing the data with a non-linearity we perform matrix multiplication between weights and input, add bias\n",
    "    #squash with a nonlinearity, for probabiolity value\n",
    "    #tanh is mostly prefered in RNN, sigmoids are great for generating O/P probabilities. They are mostly seen at the end whether in CNN or RNN as it helps in describing our O/P probability.\n",
    "    #sigmoid takes time to converge and tanh is faster.\n",
    "    next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b)  # Broadcasted addition\n",
    "    #now we append the list with the next state value and store the state in memory\n",
    "    #so this list is going to be filled with sequence of learned hidden states. This is the memory aspect of RNN.\n",
    "    #we are remembering each step through time.\n",
    "    #remember every hidden state value and its not just it remembers it and throws them in to space, but it stores them in a list, stores them in to memory data structure.\n",
    "    states_series.append(next_state)\n",
    "    #then we set current state to next one\n",
    "    #if you recall data structure and and algorithm this is very similar to linked list, where we set set head or current_pointer node to the current node's next part. Its logic is similar to that.\n",
    "    current_state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*fdwNNJ5UOE3Sx0R_Cyfmyg.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*fdwNNJ5UOE3Sx0R_Cyfmyg.png\")\n",
    "#concatenation occurs through matrix multiplication operation, then we multiply it by weights and add bias before squashing the input with a non linearity and we get a next state.\n",
    "#we store all these states over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate loss\n",
    "#second part of forward pass\n",
    "#logits short for logistic transform\n",
    "#its outputs values that we are going to squash at very end with a softmax which is going to give us a prediction.\n",
    "logits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted addition\n",
    "#apply softmax nonlinearity for output probability, prediction_series is the ending non-linearity, basically list of all our predictions over time. \n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "#measure loss, calculate softmax again on logits, then compute cross entropy\n",
    "#measures the difference between two probability distributions and that difference we have to minimise\n",
    "#this will return A Tensor of the same shape as labels and of the same type as logits \n",
    "#with the softmax cross entropy loss.\n",
    "#In our example the classes are mutually exclusive (they are either zero or one), \n",
    "#which is the reason for using the “Sparse-softmax”.\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "#computes average, gives one value which is total loss after 1 forward pass that we want to minimise.\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "#use adagrad to minimize with 0.3 learning rate\n",
    "#minimize it with adagrad, not SGD\n",
    "#One downside of SGD is that it is sensitive to\n",
    "#the learning rate hyper-parameter. When the data are sparse and features have\n",
    "#different frequencies, a single learning rate for every weight update can have\n",
    "#exponential regret.\n",
    "#sometimes features that are very important and for some reason our Neural Network does not weigh them properly.\n",
    "#because it uses same learning rate across all features, may be because its sparse data, but sometimes sparse features can also be very important to us.\n",
    "#Some features can be extremely useful and informative to an optimization problem but \n",
    "#they may not show up in most of the training instances or data. If, when they do show up, \n",
    "#they are weighted equally in terms of learning rate as a feature that has shown up hundreds \n",
    "#of times we are practically saying that the influence of such features means nothing in the \n",
    "#overall optimization. it's impact per step in the stochastic gradient descent will be so small \n",
    "#that it can practically be discounted). To counter this, AdaGrad makes it such that features \n",
    "#that are more sparse in the data have a higher learning rate which translates into a larger \n",
    "#update for that feature\n",
    "#sparse features can be very useful.\n",
    "#Each feature has a different learning rate which is adaptable. \n",
    "#gives voice to the little guy who matters a lot\n",
    "#weights that receive high gradients will have their effective learning rate reduced, \n",
    "#while weights that receive small or infrequent updates will have their effective learning rate increased. \n",
    "#great paper http://seed.ucsd.edu/mediawiki/images/6/6a/Adagrad.pdf\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualizer\n",
    "#plots training input, training output and current predictions of our network.\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/adityasharma101993/.local/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72303cd690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Loss 0.904281\n",
      "Step 100 Loss 0.575372\n",
      "Step 200 Loss 0.0231487\n",
      "Step 300 Loss 0.00871894\n",
      "Step 400 Loss 0.00549712\n",
      "Step 500 Loss 0.00396285\n",
      "Step 600 Loss 0.00318456\n",
      "New data, epoch 1\n",
      "Step 0 Loss 0.201201\n",
      "Step 100 Loss 0.00286406\n",
      "Step 200 Loss 0.00390953\n",
      "Step 300 Loss 0.00260404\n",
      "Step 400 Loss 0.00210368\n",
      "Step 500 Loss 0.00166749\n",
      "Step 600 Loss 0.00143025\n",
      "New data, epoch 2\n",
      "Step 0 Loss 0.263851\n",
      "Step 100 Loss 0.00148293\n",
      "Step 200 Loss 0.0012379\n",
      "Step 300 Loss 0.00113345\n",
      "Step 400 Loss 0.000945695\n",
      "Step 500 Loss 0.000888742\n",
      "Step 600 Loss 0.000914599\n",
      "New data, epoch 3\n",
      "Step 0 Loss 0.275884\n",
      "Step 100 Loss 0.000916197\n",
      "Step 200 Loss 0.000917977\n",
      "Step 300 Loss 0.000744618\n",
      "Step 400 Loss 0.000842856\n",
      "Step 500 Loss 0.000650454\n",
      "Step 600 Loss 0.000657852\n",
      "New data, epoch 4\n",
      "Step 0 Loss 0.372089\n",
      "Step 100 Loss 0.000758856\n",
      "Step 200 Loss 0.000594098\n",
      "Step 300 Loss 0.000622839\n",
      "Step 400 Loss 0.000553201\n",
      "Step 500 Loss 0.000504755\n",
      "Step 600 Loss 0.000504445\n",
      "New data, epoch 5\n",
      "Step 0 Loss 0.257277\n",
      "Step 100 Loss 0.000735187\n",
      "Step 200 Loss 0.000655945\n",
      "Step 300 Loss 0.00055129\n",
      "Step 400 Loss 0.00043218\n",
      "Step 500 Loss 0.00046929\n",
      "Step 600 Loss 0.000576804\n",
      "New data, epoch 6\n",
      "Step 0 Loss 0.474051\n",
      "Step 100 Loss 0.000469293\n",
      "Step 200 Loss 0.000398074\n",
      "Step 300 Loss 0.000322763\n",
      "Step 400 Loss 0.000385143\n",
      "Step 500 Loss 0.000399841\n",
      "Step 600 Loss 0.000276602\n",
      "New data, epoch 7\n",
      "Step 0 Loss 0.185037\n",
      "Step 100 Loss 0.000413142\n",
      "Step 200 Loss 0.000319075\n",
      "Step 300 Loss 0.000300056\n",
      "Step 400 Loss 0.000469373\n",
      "Step 500 Loss 0.00030029\n",
      "Step 600 Loss 0.00033566\n",
      "New data, epoch 8\n",
      "Step 0 Loss 0.296082\n",
      "Step 100 Loss 0.00034987\n",
      "Step 200 Loss 0.000320536\n",
      "Step 300 Loss 0.000324132\n",
      "Step 400 Loss 0.000288542\n",
      "Step 500 Loss 0.000341838\n",
      "Step 600 Loss 0.000266748\n",
      "New data, epoch 9\n",
      "Step 0 Loss 0.127731\n",
      "Step 100 Loss 0.0002798\n",
      "Step 200 Loss 0.000268651\n",
      "Step 300 Loss 0.000252751\n",
      "Step 400 Loss 0.000272921\n",
      "Step 500 Loss 0.000223726\n",
      "Step 600 Loss 0.000294995\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f723c842590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Step 3 Training the network\n",
    "##this is a class that runs all the tensorflow operations and launches the graph in a session. \n",
    "#All the operations have to be within the indentation. \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    #interactive mode\n",
    "    plt.ion()\n",
    "    #initialize the figure\n",
    "    plt.figure()\n",
    "    #show the graph\n",
    "    plt.show()\n",
    "    #to show the loss decrease over time\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        #generate data at every epoch, batches run in epochs\n",
    "        #output binary sequences will be a copy but shifted over echo.\n",
    "        x,y = generateData()\n",
    "        #initialize an empty hidden state\n",
    "        _current_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "        #each batch\n",
    "        for batch_idx in range(num_batches):\n",
    "            #starting and ending point per batch\n",
    "            #since weights reoccur at every layer through time\n",
    "            #These layers will not be unrolled to the beginning of time, \n",
    "            #that would be too computationally expensive, and are therefore truncated \n",
    "            #at a limited number of time-steps\n",
    "            #so it remembers the most recent hidden state and not all previous states.\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "            \n",
    "            #run the computation graph, give it the values\n",
    "            #we calculated earlier\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder:batchX,\n",
    "                    batchY_placeholder:batchY,\n",
    "                    init_state:_current_state\n",
    "                })\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Blue bars denote a training input signal (binary one), \n",
    "#red bars show echos in the training output \n",
    "#and green bars are the echos the net is generating. \n",
    "#The different bar plots show different sample series in the current batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*uKuUKp_m55zAPCzaIemucA.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*uKuUKp_m55zAPCzaIemucA.png\")\n",
    "#Time series of squares, the elevated black square symbolizes an echo-output, which is activated \n",
    "#three steps from the echo input (black square). \n",
    "#The sliding batch window is also striding three steps at each run, \n",
    "#which in our sample case means that no batch will encapsulate the dependency, so it can not train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*ytquMdmGMJo0-3kxMCi1Gg.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*ytquMdmGMJo0-3kxMCi1Gg.png\")\n",
    "#Visualization of the loss, input and output training data (blue, red) as well as the prediction (green).\n",
    "#The reason for the spikes is that we are starting on a new epoch, \n",
    "#and generating new data. Since the matrix is reshaped, \n",
    "#the first element on each row is adjacent to the last element in the previous row. \n",
    "#The first few elements on all rows (except the first) have dependencies \n",
    "#that will not be included in the state, so the net will always perform badly on the first batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
